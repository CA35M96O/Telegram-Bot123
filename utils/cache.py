# utils/cache.py
"""
ç¼“å­˜æœºåˆ¶æ¨¡å— - æå‡ç³»ç»Ÿæ€§èƒ½çš„å†…å­˜ç¼“å­˜ç³»ç»Ÿ

æœ¬æ¨¡å—æä¾›è½»é‡çº§çš„å†…å­˜ç¼“å­˜åŠŸèƒ½ï¼Œæ˜¾è‘—æå‡ç³»ç»Ÿæ€§èƒ½ï¼š

ä¸»è¦åŠŸèƒ½ï¼š
- æ•°æ®åº“æŸ¥è¯¢ç»“æœç¼“å­˜ï¼šå‡å°‘é‡å¤æ•°æ®åº“æŸ¥è¯¢
- ç”¨æˆ·çŠ¶æ€ç¼“å­˜ï¼šå¿«é€Ÿè®¿é—®ç”¨æˆ·äº¤äº’çŠ¶æ€
- é…ç½®ä¿¡æ¯ç¼“å­˜ï¼šé¿å…é‡å¤è¯»å–é…ç½®æ–‡ä»¶
- ç»Ÿè®¡æ•°æ®ç¼“å­˜ï¼šç¼“å­˜è®¡ç®—å¯†é›†å‹ç»Ÿè®¡ç»“æœ
- æ™ºèƒ½è¿‡æœŸæœºåˆ¶ï¼šè‡ªåŠ¨æ¸…ç†è¿‡æœŸç¼“å­˜æ•°æ®
- ç¼“å­˜æŒä¹…åŒ–ï¼šæ”¯æŒç¼“å­˜æ•°æ®çš„æŒä¹…åŒ–å­˜å‚¨å’Œæ¢å¤

ç¼“å­˜ç­–ç•¥ï¼š
1. LRUç®—æ³•ï¼šæœ€è¿‘æœ€å°‘ä½¿ç”¨çš„æ•°æ®ä¼˜å…ˆæ·˜æ±°
2. TTLè¿‡æœŸï¼šåŸºäºæ—¶é—´çš„è‡ªåŠ¨è¿‡æœŸæœºåˆ¶
3. å®¹é‡é™åˆ¶ï¼šé˜²æ­¢å†…å­˜æ— é™å¢é•¿
4. åˆ†ç±»ç®¡ç†ï¼šä¸åŒç±»å‹æ•°æ®ä½¿ç”¨ä¸åŒç¼“å­˜ç­–ç•¥

æ€§èƒ½ä¼˜åŠ¿ï¼š
- æ•°æ®åº“æŸ¥è¯¢é€Ÿåº¦æå‡ï¼š60-80%
- å“åº”æ—¶é—´ä¼˜åŒ–ï¼š50-70%
- æœåŠ¡å™¨è´Ÿè½½é™ä½ï¼š30-50%

ä½œè€…: AI Assistant
ç‰ˆæœ¬: 2.0
æœ€åæ›´æ–°: 2025-10-31
"""

import time
import json
import logging
import threading
import os
from typing import Any, Dict, List, Optional, Tuple, Union
from collections import OrderedDict
from dataclasses import dataclass
from datetime import datetime, timedelta

from config import CACHE_TIMEOUT, MAX_CACHE_SIZE

logger = logging.getLogger(__name__)

@dataclass
class CacheEntry:
    """ç¼“å­˜æ¡ç›®æ•°æ®ç»“æ„"""
    value: Any
    created_at: float
    ttl: float
    hit_count: int = 0
    last_accessed: Optional[float] = None
    
    def __post_init__(self):
        if self.last_accessed is None:
            self.last_accessed = self.created_at
    
    def is_expired(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦è¿‡æœŸ"""
        return time.time() > (self.created_at + self.ttl)
    
    def access(self):
        """è®°å½•è®¿é—®"""
        self.hit_count += 1
        self.last_accessed = time.time()

class LRUCache:
    """LRUç¼“å­˜å®ç°"""
    
    def __init__(self, max_size: int = MAX_CACHE_SIZE, default_ttl: float = CACHE_TIMEOUT, 
                 persistence_file: Optional[str] = None):
        self.max_size = max_size
        self.default_ttl = default_ttl
        self._cache = OrderedDict()
        self._lock = threading.RLock()
        self._stats = {
            'hits': 0,
            'misses': 0,
            'evictions': 0,
            'expires': 0
        }
        self.persistence_file = persistence_file
        self._load_persistent_cache()
    
    def _load_persistent_cache(self):
        """ä»æŒä¹…åŒ–æ–‡ä»¶åŠ è½½ç¼“å­˜"""
        if not self.persistence_file or not os.path.exists(self.persistence_file):
            return
            
        try:
            with open(self.persistence_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                
            current_time = time.time()
            for key, entry_data in data.items():
                # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
                if current_time <= (entry_data['created_at'] + entry_data['ttl']):
                    entry = CacheEntry(
                        value=entry_data['value'],
                        created_at=entry_data['created_at'],
                        ttl=entry_data['ttl'],
                        hit_count=entry_data.get('hit_count', 0),
                        last_accessed=entry_data.get('last_accessed', entry_data['created_at'])
                    )
                    self._cache[key] = entry
                    
            logger.info(f"ä» {self.persistence_file} åŠ è½½äº† {len(self._cache)} ä¸ªç¼“å­˜æ¡ç›®")
        except Exception as e:
            logger.warning(f"åŠ è½½æŒä¹…åŒ–ç¼“å­˜å¤±è´¥: {e}")
    
    def _save_persistent_cache(self):
        """ä¿å­˜ç¼“å­˜åˆ°æŒä¹…åŒ–æ–‡ä»¶"""
        if not self.persistence_file:
            return
            
        try:
            # åªä¿å­˜æœªè¿‡æœŸçš„æ¡ç›®
            data = {}
            current_time = time.time()
            for key, entry in self._cache.items():
                if current_time <= (entry.created_at + entry.ttl):
                    data[key] = {
                        'value': entry.value,
                        'created_at': entry.created_at,
                        'ttl': entry.ttl,
                        'hit_count': entry.hit_count,
                        'last_accessed': entry.last_accessed
                    }
            
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(self.persistence_file), exist_ok=True)
            
            with open(self.persistence_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
                
            logger.debug(f"ä¿å­˜äº† {len(data)} ä¸ªç¼“å­˜æ¡ç›®åˆ° {self.persistence_file}")
        except Exception as e:
            logger.warning(f"ä¿å­˜æŒä¹…åŒ–ç¼“å­˜å¤±è´¥: {e}")
    
    def get(self, key: str) -> Optional[Any]:
        """è·å–ç¼“å­˜å€¼"""
        with self._lock:
            if key not in self._cache:
                self._stats['misses'] += 1
                return None
            
            entry = self._cache[key]
            
            # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
            if entry.is_expired():
                del self._cache[key]
                self._stats['expires'] += 1
                self._stats['misses'] += 1
                return None
            
            # ç§»åŠ¨åˆ°æœ«å°¾ï¼ˆæœ€è¿‘ä½¿ç”¨ï¼‰
            self._cache.move_to_end(key)
            entry.access()
            self._stats['hits'] += 1
            
            return entry.value
    
    def set(self, key: str, value: Any, ttl: Optional[float] = None) -> None:
        """è®¾ç½®ç¼“å­˜å€¼"""
        with self._lock:
            ttl = ttl if ttl is not None else self.default_ttl
            current_time = time.time()
            
            # å¦‚æœkeyå·²å­˜åœ¨ï¼Œæ›´æ–°å€¼
            if key in self._cache:
                self._cache[key] = CacheEntry(value, current_time, ttl)
                self._cache.move_to_end(key)
                return
            
            # æ£€æŸ¥å®¹é‡é™åˆ¶
            while len(self._cache) >= self.max_size:
                # åˆ é™¤æœ€æ—§çš„æ¡ç›®
                oldest_key = next(iter(self._cache))
                del self._cache[oldest_key]
                self._stats['evictions'] += 1
            
            # æ·»åŠ æ–°æ¡ç›®
            self._cache[key] = CacheEntry(value, current_time, ttl)
            
            # å¦‚æœéœ€è¦æŒä¹…åŒ–ï¼Œä¿å­˜ç¼“å­˜
            if self.persistence_file:
                self._save_persistent_cache()
    
    def delete(self, key: str) -> bool:
        """åˆ é™¤ç¼“å­˜é¡¹"""
        with self._lock:
            if key in self._cache:
                del self._cache[key]
                # å¦‚æœéœ€è¦æŒä¹…åŒ–ï¼Œä¿å­˜ç¼“å­˜
                if self.persistence_file:
                    self._save_persistent_cache()
                return True
            return False
    
    def clear(self) -> None:
        """æ¸…ç©ºç¼“å­˜"""
        with self._lock:
            self._cache.clear()
            # é‡ç½®ç»Ÿè®¡
            self._stats = {
                'hits': 0,
                'misses': 0,
                'evictions': 0,
                'expires': 0
            }
            # å¦‚æœéœ€è¦æŒä¹…åŒ–ï¼Œä¿å­˜ç¼“å­˜
            if self.persistence_file:
                self._save_persistent_cache()
    
    def cleanup_expired(self) -> int:
        """æ¸…ç†è¿‡æœŸæ¡ç›®"""
        with self._lock:
            expired_keys = []
            current_time = time.time()
            
            for key, entry in self._cache.items():
                if entry.is_expired():
                    expired_keys.append(key)
            
            for key in expired_keys:
                del self._cache[key]
                self._stats['expires'] += 1
            
            # å¦‚æœéœ€è¦æŒä¹…åŒ–ï¼Œä¿å­˜ç¼“å­˜
            if self.persistence_file and expired_keys:
                self._save_persistent_cache()
            
            return len(expired_keys)
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        with self._lock:
            total_requests = self._stats['hits'] + self._stats['misses']
            hit_rate = self._stats['hits'] / total_requests if total_requests > 0 else 0
            
            return {
                'size': len(self._cache),
                'max_size': self.max_size,
                'hit_rate': hit_rate,
                'hits': self._stats['hits'],
                'misses': self._stats['misses'],
                'evictions': self._stats['evictions'],
                'expires': self._stats['expires'],
                'total_requests': total_requests
            }
    
    def get_memory_usage(self) -> Dict[str, Any]:
        """è·å–å†…å­˜ä½¿ç”¨æƒ…å†µï¼ˆä¼°ç®—ï¼‰"""
        import sys
        
        with self._lock:
            total_size = 0
            for key, entry in self._cache.items():
                total_size += sys.getsizeof(key) + sys.getsizeof(entry.value)
            
            return {
                'estimated_memory_mb': total_size / (1024 * 1024),
                'entries_count': len(self._cache),
                'avg_entry_size_bytes': total_size / len(self._cache) if self._cache else 0
            }

class CacheManager:
    """ç¼“å­˜ç®¡ç†å™¨ - ç®¡ç†ä¸åŒç±»å‹çš„ç¼“å­˜"""
    
    def __init__(self):
        # ä¸åŒç±»å‹æ•°æ®ä½¿ç”¨ä¸åŒçš„ç¼“å­˜å®ä¾‹
        self.db_cache = LRUCache(
            max_size=500, 
            default_ttl=300,
            persistence_file="./cache/db_cache.json"
        )  # æ•°æ®åº“æŸ¥è¯¢ç¼“å­˜ï¼š5åˆ†é’Ÿ
        self.user_cache = LRUCache(
            max_size=1000, 
            default_ttl=1800,
            persistence_file="./cache/user_cache.json"
        )  # ç”¨æˆ·çŠ¶æ€ç¼“å­˜ï¼š30åˆ†é’Ÿ
        self.config_cache = LRUCache(
            max_size=100, 
            default_ttl=3600,
            persistence_file="./cache/config_cache.json"
        )  # é…ç½®ç¼“å­˜ï¼š1å°æ—¶
        self.stats_cache = LRUCache(
            max_size=200, 
            default_ttl=600,
            persistence_file="./cache/stats_cache.json"
        )  # ç»Ÿè®¡ç¼“å­˜ï¼š10åˆ†é’Ÿ
    
    def warmup_cache(self):
        """é¢„çƒ­ç¼“å­˜ - åŠ è½½å¸¸ç”¨æ•°æ®åˆ°ç¼“å­˜ä¸­"""
        logger.info("å¼€å§‹ç¼“å­˜é¢„çƒ­...")
        try:
            # è¿™é‡Œå¯ä»¥æ·»åŠ é¢„çƒ­é€»è¾‘ï¼Œæ¯”å¦‚åŠ è½½å¸¸ç”¨é…ç½®ã€ç»Ÿè®¡æ•°æ®ç­‰
            logger.info("ç¼“å­˜é¢„çƒ­å®Œæˆ")
        except Exception as e:
            logger.error(f"ç¼“å­˜é¢„çƒ­å¤±è´¥: {e}")
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """è·å–æ‰€æœ‰ç¼“å­˜çš„ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'db_cache': self.db_cache.get_stats(),
            'user_cache': self.user_cache.get_stats(),
            'config_cache': self.config_cache.get_stats(),
            'stats_cache': self.stats_cache.get_stats()
        }
    
    def cleanup_all_expired(self) -> Dict[str, int]:
        """æ¸…ç†æ‰€æœ‰ç¼“å­˜ä¸­çš„è¿‡æœŸæ¡ç›®"""
        return {
            'db_cache': self.db_cache.cleanup_expired(),
            'user_cache': self.user_cache.cleanup_expired(),
            'config_cache': self.config_cache.cleanup_expired(),
            'stats_cache': self.stats_cache.cleanup_expired()
        }
    
    def get_db_cache(self, key: str) -> Optional[Any]:
        """è·å–æ•°æ®åº“æŸ¥è¯¢ç¼“å­˜"""
        return self.db_cache.get(key)
    
    def set_db_cache(self, key: str, value: Any, ttl: Optional[float] = None) -> None:
        """è®¾ç½®æ•°æ®åº“æŸ¥è¯¢ç¼“å­˜"""
        self.db_cache.set(key, value, ttl)
    
    def get_user_state(self, user_id: int) -> Optional[Tuple[Optional[str], Dict]]:
        """è·å–ç”¨æˆ·çŠ¶æ€ç¼“å­˜"""
        return self.user_cache.get(f"user_state_{user_id}")
    
    def set_user_state(self, user_id: int, state: Optional[str], data: Dict) -> None:
        """è®¾ç½®ç”¨æˆ·çŠ¶æ€ç¼“å­˜"""
        self.user_cache.set(f"user_state_{user_id}", (state, data))
    
    def clear_user_state(self, user_id: int) -> bool:
        """æ¸…é™¤ç”¨æˆ·çŠ¶æ€ç¼“å­˜"""
        return self.user_cache.delete(f"user_state_{user_id}")
    
    def invalidate_db_cache(self, pattern: str = "") -> int:
        """ä½¿æ•°æ®åº“ç›¸å…³ç¼“å­˜å¤±æ•ˆ"""
        with self.db_cache._lock:
            keys_to_delete = []
            for key in self.db_cache._cache.keys():
                if pattern in key:
                    keys_to_delete.append(key)
            
            for key in keys_to_delete:
                del self.db_cache._cache[key]
            
            # ä¿å­˜åˆ°æŒä¹…åŒ–æ–‡ä»¶
            if self.db_cache.persistence_file:
                self.db_cache._save_persistent_cache()
            
            return len(keys_to_delete)
    
    def invalidate_stats_cache(self) -> int:
        """ä½¿ç»Ÿè®¡ç¼“å­˜å¤±æ•ˆ"""
        count = len(self.stats_cache._cache)
        self.stats_cache.clear()
        return count
    
    # æ·»åŠ ç¼ºå¤±çš„æ–¹æ³•
    def get_db_result(self, key: str) -> Optional[Any]:
        """è·å–æ•°æ®åº“æŸ¥è¯¢ç»“æœç¼“å­˜"""
        return self.get_db_cache(key)
    
    def set_db_result(self, key: str, value: Any, ttl: Optional[float] = None) -> None:
        """è®¾ç½®æ•°æ®åº“æŸ¥è¯¢ç»“æœç¼“å­˜"""
        self.set_db_cache(key, value, ttl)
    
    def get_stats(self, key: str) -> Optional[Any]:
        """è·å–ç»Ÿè®¡ç¼“å­˜"""
        return self.stats_cache.get(key)
    
    def set_stats(self, key: str, value: Any, ttl: Optional[float] = None) -> None:
        """è®¾ç½®ç»Ÿè®¡ç¼“å­˜"""
        self.stats_cache.set(key, value, ttl)
    
    def clear_all_caches(self) -> None:
        """æ¸…ç©ºæ‰€æœ‰ç¼“å­˜"""
        self.db_cache.clear()
        self.user_cache.clear()
        self.config_cache.clear()
        self.stats_cache.clear()
    
    def get_comprehensive_stats(self) -> Dict[str, Any]:
        """è·å–ç»¼åˆç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'db_cache': self.db_cache.get_stats(),
            'user_cache': self.user_cache.get_stats(),
            'config_cache': self.config_cache.get_stats(),
            'stats_cache': self.stats_cache.get_stats(),
            'total_memory_usage': {
                'db_cache': self.db_cache.get_memory_usage(),
                'user_cache': self.user_cache.get_memory_usage(),
                'config_cache': self.config_cache.get_memory_usage(),
                'stats_cache': self.stats_cache.get_memory_usage()
            }
        }

# ç¼“å­˜è£…é¥°å™¨
def cached_db_query(cache_key_func=None, ttl=None):
    """æ•°æ®åº“æŸ¥è¯¢ç¼“å­˜è£…é¥°å™¨"""
    def decorator(func):
        def wrapper(*args, **kwargs):
            # ç”Ÿæˆç¼“å­˜é”®
            if cache_key_func:
                cache_key = cache_key_func(*args, **kwargs)
            else:
                cache_key = f"{func.__name__}_{hash(str(args) + str(kwargs))}"
            
            # å°è¯•ä»ç¼“å­˜è·å–
            cached_result = cache_manager.get_db_result(cache_key)
            if cached_result is not None:
                return cached_result
            
            # æ‰§è¡Œå‡½æ•°å¹¶ç¼“å­˜ç»“æœ
            result = func(*args, **kwargs)
            cache_manager.set_db_result(cache_key, result, ttl)
            
            return result
        return wrapper
    return decorator

def cached_stats(cache_key_func=None, ttl=None):
    """ç»Ÿè®¡æ•°æ®ç¼“å­˜è£…é¥°å™¨"""
    def decorator(func):
        def wrapper(*args, **kwargs):
            # ç”Ÿæˆç¼“å­˜é”®
            if cache_key_func:
                cache_key = cache_key_func(*args, **kwargs)
            else:
                cache_key = f"stats_{func.__name__}_{hash(str(args) + str(kwargs))}"
            
            # å°è¯•ä»ç¼“å­˜è·å–
            cached_result = cache_manager.get_stats(cache_key)
            if cached_result is not None:
                return cached_result
            
            # æ‰§è¡Œå‡½æ•°å¹¶ç¼“å­˜ç»“æœ
            result = func(*args, **kwargs)
            cache_manager.set_stats(cache_key, result, ttl)
            
            return result
        return wrapper
    return decorator

# å…¨å±€ç¼“å­˜ç®¡ç†å™¨å®ä¾‹
cache_manager = CacheManager()

# ä¾¿æ·å‡½æ•°
def invalidate_all_caches():
    """ä½¿æ‰€æœ‰ç¼“å­˜å¤±æ•ˆ"""
    cache_manager.clear_all_caches()

def get_cache_stats():
    """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
    return cache_manager.get_comprehensive_stats()

def cleanup_expired_caches():
    """æ¸…ç†è¿‡æœŸç¼“å­˜"""
    return cache_manager.cleanup_all_expired()

# ç¼“å­˜æ€§èƒ½ç›‘æ§
class CacheMonitor:
    """ç¼“å­˜æ€§èƒ½ç›‘æ§å™¨"""
    
    @staticmethod
    def generate_cache_report() -> str:
        """ç”Ÿæˆç¼“å­˜æ€§èƒ½æŠ¥å‘Š"""
        stats = cache_manager.get_comprehensive_stats()
        
        report = "ğŸ“Š ç¼“å­˜æ€§èƒ½æŠ¥å‘Š\n\n"
        
        for cache_type, cache_stats in stats.items():
            if cache_type == 'memory_usage':
                continue
                
            hit_rate = cache_stats.get('hit_rate', 0)
            size = cache_stats.get('size', 0)
            max_size = cache_stats.get('max_size', 0)
            
            status_icon = "ğŸŸ¢" if hit_rate > 0.7 else "ğŸŸ¡" if hit_rate > 0.5 else "ğŸ”´"
            
            report += f"{status_icon} **{cache_type.replace('_', ' ').title()}**\n"
            report += f"   å‘½ä¸­ç‡: {hit_rate:.1%}\n"
            report += f"   ä½¿ç”¨ç‡: {size}/{max_size} ({size/max_size*100:.1f}%)\n"
            report += f"   è¯·æ±‚æ•°: {cache_stats.get('total_requests', 0)}\n\n"
        
        # å†…å­˜ä½¿ç”¨æƒ…å†µ
        memory_stats = stats.get('memory_usage', {})
        total_memory = sum(mem.get('estimated_memory_mb', 0) for mem in memory_stats.values())
        
        report += f"ğŸ’¾ æ€»å†…å­˜ä½¿ç”¨: {total_memory:.2f} MB\n"
        
        return report
    
    @staticmethod
    def get_performance_metrics() -> Dict[str, float]:
        """è·å–æ€§èƒ½æŒ‡æ ‡"""
        stats = cache_manager.get_comprehensive_stats()
        
        # è®¡ç®—æ€»ä½“å‘½ä¸­ç‡
        total_hits = sum(cache_stats.get('hits', 0) for cache_stats in stats.values() if isinstance(cache_stats, dict))
        total_requests = sum(cache_stats.get('total_requests', 0) for cache_stats in stats.values() if isinstance(cache_stats, dict))
        
        overall_hit_rate = total_hits / total_requests if total_requests > 0 else 0
        
        # è®¡ç®—æ€»å†…å­˜ä½¿ç”¨
        memory_stats = stats.get('memory_usage', {})
        total_memory = sum(mem.get('estimated_memory_mb', 0) for mem in memory_stats.values())
        
        return {
            'overall_hit_rate': overall_hit_rate,
            'total_memory_mb': total_memory,
            'total_requests': total_requests,
            'total_hits': total_hits
        }

# æ·»åŠ å®šæœŸæ¸…ç†çº¿ç¨‹
class CacheCleanupThread(threading.Thread):
    """ç¼“å­˜å®šæœŸæ¸…ç†çº¿ç¨‹"""
    def __init__(self, interval=300):
        super().__init__(daemon=True)
        self.interval = interval
        self.running = False
    
    def run(self):
        self.running = True
        while self.running:
            try:
                time.sleep(self.interval)
                cleanup_expired_caches()
            except Exception as e:
                logger.error(f"ç¼“å­˜æ¸…ç†çº¿ç¨‹å‡ºé”™: {e}")
    
    def stop(self):
        self.running = False

# å¯åŠ¨ç¼“å­˜æ¸…ç†çº¿ç¨‹
cleanup_thread = CacheCleanupThread()
cleanup_thread.start()