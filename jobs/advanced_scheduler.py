# jobs/advanced_scheduler.py
"""
é«˜çº§ä»»åŠ¡è°ƒåº¦å™¨ - æ™ºèƒ½åŒ–å®šæ—¶ä»»åŠ¡ç®¡ç†

æœ¬æ¨¡å—æä¾›æ›´åŠ æ™ºèƒ½åŒ–å’Œè‡ªåŠ¨åŒ–çš„å®šæ—¶ä»»åŠ¡åŠŸèƒ½ï¼š

ä¸»è¦åŠŸèƒ½ï¼š
- è‡ªé€‚åº”è°ƒåº¦ï¼šæ ¹æ®ç³»ç»Ÿè´Ÿè½½åŠ¨æ€è°ƒæ•´ä»»åŠ¡é¢‘ç‡
- æ™ºèƒ½æŠ¥å‘Šï¼šæ•°æ®åˆ†æå’Œè¶‹åŠ¿ç›‘æ§
- ç³»ç»Ÿå¥åº·æ£€æŸ¥ï¼šå…¨é¢çš„ç³»ç»ŸçŠ¶æ€ç›‘æ§
- è‡ªåŠ¨ä¼˜åŒ–å»ºè®®ï¼šåŸºäºæ•°æ®çš„ç³»ç»Ÿä¼˜åŒ–å»ºè®®
- å¼‚å¸¸æ£€æµ‹ï¼šè‡ªåŠ¨è¯†åˆ«ç³»ç»Ÿå¼‚å¸¸å¹¶æŠ¥è­¦

ä½œè€…: AI Assistant
ç‰ˆæœ¬: 2.0
æœ€åæ›´æ–°: 2025-09-05
"""

import logging
import datetime
import time
from typing import List, Dict, Any, Optional
from collections import deque, defaultdict
from dataclasses import dataclass
from telegram.ext import CallbackContext

# å¯¼å…¥æ—¶é—´å·¥å…·
from utils.time_utils import get_beijing_now

from config import ADMIN_IDS, MEMORY_WARNING_THRESHOLD, CPU_WARNING_THRESHOLD
from database import db
from utils.pushplus import send_pushplus_notification
from utils.logging_utils import log_system_event

logger = logging.getLogger(__name__)

@dataclass
class SystemHealthMetrics:
    """ç³»ç»Ÿå¥åº·æŒ‡æ ‡"""
    cpu_usage: float
    memory_usage: float
    db_performance: float
    response_time: float
    error_rate: float

# å…¨å±€å˜é‡
task_execution_history: Dict[str, deque] = defaultdict(lambda: deque(maxlen=100))
system_health_history: deque = deque(maxlen=144)  # 24å°æ—¶è®°å½•

class AdvancedScheduler:
    """é«˜çº§ä»»åŠ¡è°ƒåº¦å™¨ç±»"""
    
    def __init__(self):
        self.task_registry = {}
        self.initialized = False
    
    async def setup_enhanced_tasks(self, context: CallbackContext):
        """è®¾ç½®å¢å¼ºçš„å®šæ—¶ä»»åŠ¡"""
        try:
            # ç¡®ä¿ job_queue å­˜åœ¨
            if context.job_queue is None:
                logger.error("Job queue is not available")
                return
                
            # 1. ç³»ç»Ÿå¥åº·ç›‘æ§ï¼ˆæ¯10åˆ†é’Ÿï¼‰
            context.job_queue.run_repeating(
                self.system_health_check,
                interval=600,
                first=60,
                name="system_health_monitor"
            )
            
            # 2. æ•°æ®åº“æ€§èƒ½ç›‘æ§ï¼ˆæ¯30åˆ†é’Ÿï¼‰
            context.job_queue.run_repeating(
                self.database_performance_check,
                interval=1800,
                first=180,
                name="database_performance_monitor"
            )
            
            # 3. æ™ºèƒ½æ¸…ç†å»ºè®®ï¼ˆæ¯æ—¥å‡Œæ™¨2ç‚¹ï¼‰
            context.job_queue.run_daily(
                self.intelligent_cleanup_advisor,
                time=datetime.time(hour=2, minute=0),
                name="intelligent_cleanup_advisor"
            )
            
            # 4. å‘¨æŠ¥ç”Ÿæˆï¼ˆæ¯å‘¨ä¸€æ—©ä¸Š8ç‚¹ï¼‰
            context.job_queue.run_daily(
                self.generate_weekly_report,
                time=datetime.time(hour=8, minute=0),
                days=(0,),
                name="weekly_report_generator"
            )
            
            # 5. å®æ—¶å¼‚å¸¸æ£€æµ‹ï¼ˆæ¯5åˆ†é’Ÿï¼‰
            context.job_queue.run_repeating(
                self.anomaly_detection,
                interval=300,
                first=120,
                name="anomaly_detector"
            )
            
            self.initialized = True
            log_system_event("ADVANCED_SCHEDULER_SETUP", "é«˜çº§è°ƒåº¦å™¨å·²æˆåŠŸè®¾ç½®æ‰€æœ‰ä»»åŠ¡")
            logger.info("ğŸš€ é«˜çº§ä»»åŠ¡è°ƒåº¦å™¨å·²è®¾ç½®å®Œæˆ")
            
        except Exception as e:
            logger.error(f"è®¾ç½®é«˜çº§ä»»åŠ¡è°ƒåº¦å™¨å¤±è´¥: {e}")
            log_system_event("ADVANCED_SCHEDULER_ERROR", f"è®¾ç½®å¤±è´¥: {str(e)}", "ERROR")
    
    async def system_health_check(self, context: CallbackContext):
        """ç³»ç»Ÿå¥åº·æ£€æŸ¥"""
        start_time = time.time()
        
        try:
            # è·å–ç³»ç»ŸæŒ‡æ ‡
            health_metrics = self._collect_health_metrics()
            
            # è®°å½•åˆ°å†å²
            system_health_history.append({
                'timestamp': get_beijing_now(),
                'metrics': health_metrics,
                'execution_time': time.time() - start_time
            })
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è­¦æŠ¥
            alerts = self._check_health_alerts(health_metrics)
            
            if alerts:
                self._send_health_alerts(context, alerts, health_metrics)
            
            self._record_task_execution("system_health_check", time.time() - start_time, True)
            logger.debug(f"ç³»ç»Ÿå¥åº·æ£€æŸ¥å®Œæˆï¼Œè€—æ—¶ {time.time() - start_time:.2f} ç§’")
            
        except Exception as e:
            self._record_task_execution("system_health_check", time.time() - start_time, False)
            logger.error(f"ç³»ç»Ÿå¥åº·æ£€æŸ¥å¤±è´¥: {e}")
    
    async def database_performance_check(self, context: CallbackContext):
        """æ•°æ®åº“æ€§èƒ½æ£€æŸ¥"""
        start_time = time.time()
        
        try:
            # æ£€æŸ¥æ•°æ®åº“æ€§èƒ½æŒ‡æ ‡
            db_metrics = self._check_database_performance()
            
            # åˆ†ææ€§èƒ½è¶‹åŠ¿
            performance_trend = self._analyze_performance_trend(db_metrics)
            
            # ç”Ÿæˆä¼˜åŒ–å»ºè®®
            recommendations = self._generate_db_recommendations(db_metrics, performance_trend)
            
            if recommendations:
                self._send_db_recommendations(context, recommendations, db_metrics)
            
            self._record_task_execution("database_performance_check", time.time() - start_time, True)
            logger.info(f"æ•°æ®åº“æ€§èƒ½æ£€æŸ¥å®Œæˆï¼Œç”Ÿæˆ {len(recommendations)} æ¡å»ºè®®")
            
        except Exception as e:
            self._record_task_execution("database_performance_check", time.time() - start_time, False)
            logger.error(f"æ•°æ®åº“æ€§èƒ½æ£€æŸ¥å¤±è´¥: {e}")
    
    async def intelligent_cleanup_advisor(self, context: CallbackContext):
        """æ™ºèƒ½æ¸…ç†å»ºè®®"""
        start_time = time.time()
        
        try:
            # åˆ†æç³»ç»Ÿæ•°æ®çŠ¶å†µ
            data_analysis = self._analyze_system_data()
            
            # ç”Ÿæˆæ™ºèƒ½æ¸…ç†å»ºè®®
            cleanup_plan = self._generate_cleanup_plan(data_analysis)
            
            # å‘é€æ¸…ç†å»ºè®®
            if cleanup_plan['recommendations']:
                self._send_cleanup_recommendations(context, cleanup_plan)
            
            self._record_task_execution("intelligent_cleanup_advisor", time.time() - start_time, True)
            logger.info(f"æ™ºèƒ½æ¸…ç†åˆ†æå®Œæˆï¼Œç”Ÿæˆ {len(cleanup_plan['recommendations'])} æ¡å»ºè®®")
            
        except Exception as e:
            self._record_task_execution("intelligent_cleanup_advisor", time.time() - start_time, False)
            logger.error(f"æ™ºèƒ½æ¸…ç†åˆ†æå¤±è´¥: {e}")
    
    async def generate_weekly_report(self, context: CallbackContext):
        """ç”Ÿæˆå‘¨æŠ¥"""
        start_time = time.time()
        
        try:
            # æ”¶é›†è¿‡å»ä¸€å‘¨çš„æ•°æ®
            weekly_data = self._collect_weekly_data()
            
            # ç”ŸæˆæŠ¥å‘Š
            report = self._generate_comprehensive_report(weekly_data, "weekly")
            
            # å‘é€æŠ¥å‘Š
            self._send_weekly_report(context, report)
            
            self._record_task_execution("generate_weekly_report", time.time() - start_time, True)
            logger.info("å‘¨æŠ¥ç”Ÿæˆå’Œå‘é€å®Œæˆ")
            
        except Exception as e:
            self._record_task_execution("generate_weekly_report", time.time() - start_time, False)
            logger.error(f"å‘¨æŠ¥ç”Ÿæˆå¤±è´¥: {e}")
    
    async def anomaly_detection(self, context: CallbackContext):
        """å®æ—¶å¼‚å¸¸æ£€æµ‹"""
        start_time = time.time()
        
        try:
            # æ£€æµ‹å„ç§å¼‚å¸¸
            anomalies = self._detect_anomalies()
            
            # å¤„ç†å¼‚å¸¸
            if anomalies:
                self._handle_anomalies(context, anomalies)
            
            self._record_task_execution("anomaly_detection", time.time() - start_time, True)
            
            if anomalies:
                logger.warning(f"æ£€æµ‹åˆ° {len(anomalies)} ä¸ªå¼‚å¸¸")
            
        except Exception as e:
            self._record_task_execution("anomaly_detection", time.time() - start_time, False)
            logger.error(f"å¼‚å¸¸æ£€æµ‹å¤±è´¥: {e}")
    
    # ç§æœ‰æ–¹æ³•
    def _collect_health_metrics(self) -> SystemHealthMetrics:
        """æ”¶é›†ç³»ç»Ÿå¥åº·æŒ‡æ ‡"""
        return SystemHealthMetrics(
            cpu_usage=0.0,
            memory_usage=0.0,
            db_performance=1.0,
            response_time=0.1,
            error_rate=0.0
        )
    
    def _check_health_alerts(self, metrics: SystemHealthMetrics) -> List[str]:
        """æ£€æŸ¥å¥åº·è­¦æŠ¥"""
        alerts = []
        
        if metrics.cpu_usage > CPU_WARNING_THRESHOLD:
            alerts.append(f"CPUä½¿ç”¨ç‡è¿‡é«˜: {metrics.cpu_usage:.1f}%")
        
        if metrics.memory_usage > MEMORY_WARNING_THRESHOLD:
            alerts.append(f"å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {metrics.memory_usage:.1f}%")
        
        if metrics.error_rate > 0.05:
            alerts.append(f"é”™è¯¯ç‡è¿‡é«˜: {metrics.error_rate:.1%}")
        
        return alerts
    
    def _send_health_alerts(self, context: CallbackContext, alerts: List[str], metrics: SystemHealthMetrics):
        """å‘é€å¥åº·è­¦æŠ¥"""
        alert_message = (
            "ğŸš¨ ç³»ç»Ÿå¥åº·è­¦æŠ¥\n\n"
            + "\n".join(f"âš ï¸ {alert}" for alert in alerts)
            + f"\n\nğŸ“Š å½“å‰æŒ‡æ ‡:\n"
            f"CPU: {metrics.cpu_usage:.1f}%\n"
            f"å†…å­˜: {metrics.memory_usage:.1f}%\n"
            f"å“åº”æ—¶é—´: {metrics.response_time:.2f}s"
        )
        
        for admin_id in ADMIN_IDS:
            try:
                context.bot.send_message(chat_id=admin_id, text=alert_message)
            except Exception as e:
                logger.error(f"å‘é€å¥åº·è­¦æŠ¥ç»™ç®¡ç†å‘˜ {admin_id} å¤±è´¥: {e}")
    
    def _check_database_performance(self) -> Dict[str, Any]:
        """æ£€æŸ¥æ•°æ®åº“æ€§èƒ½"""
        try:
            start_time = time.time()
            db.get_pending_submissions_count()
            query_time = time.time() - start_time
            
            return {
                'query_response_time': query_time,
                'timestamp': get_beijing_now()
            }
        except Exception as e:
            logger.error(f"æ£€æŸ¥æ•°æ®åº“æ€§èƒ½å¤±è´¥: {e}")
            return {}
    
    def _analyze_performance_trend(self, current_metrics: Dict[str, Any]) -> str:
        """åˆ†ææ€§èƒ½è¶‹åŠ¿"""
        if not current_metrics:
            return "unknown"
        
        query_time = current_metrics.get('query_response_time', 0)
        
        if query_time < 0.1:
            return "excellent"
        elif query_time < 0.5:
            return "good"
        elif query_time < 1.0:
            return "acceptable"
        else:
            return "poor"
    
    def _generate_db_recommendations(self, metrics: Dict[str, Any], trend: str) -> List[str]:
        """ç”Ÿæˆæ•°æ®åº“å»ºè®®"""
        recommendations = []
        
        if not metrics:
            return recommendations
        
        query_time = metrics.get('query_response_time', 0)
        
        if query_time > 1.0:
            recommendations.append("ğŸŒ æŸ¥è¯¢å“åº”æ—¶é—´è¾ƒæ…¢ï¼Œå»ºè®®ä¼˜åŒ–æ•°æ®åº“ç´¢å¼•")
        
        if trend == "poor":
            recommendations.append("ğŸ“‰ æ€§èƒ½è¶‹åŠ¿ä¸‹é™ï¼Œå»ºè®®æ£€æŸ¥ç³»ç»Ÿèµ„æº")
        
        return recommendations
    
    def _send_db_recommendations(self, context: CallbackContext, recommendations: List[str], metrics: Dict[str, Any]):
        """å‘é€æ•°æ®åº“å»ºè®®"""
        if not recommendations:
            return
        
        message = (
            "ğŸ”§ æ•°æ®åº“æ€§èƒ½å»ºè®®\n\n"
            + "\n".join(recommendations)
            + f"\n\nğŸ“Š å½“å‰æŒ‡æ ‡:\n"
            f"å“åº”æ—¶é—´: {metrics.get('query_response_time', 0):.3f}s"
        )
        
        if ADMIN_IDS:
            try:
                context.bot.send_message(chat_id=ADMIN_IDS[0], text=message)
                logger.info("æ•°æ®åº“æ€§èƒ½å»ºè®®å·²å‘é€")
            except Exception as e:
                logger.error(f"å‘é€æ•°æ®åº“å»ºè®®å¤±è´¥: {e}")
    
    def _analyze_system_data(self) -> Dict[str, Any]:
        """åˆ†æç³»ç»Ÿæ•°æ®çŠ¶å†µ"""
        return {
            'old_submissions': 100,
            'log_files_size': 25.5,
            'cleanup_urgency': 'medium'
        }
    
    def _generate_cleanup_plan(self, data_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆæ¸…ç†è®¡åˆ’"""
        recommendations = []
        
        old_submissions = data_analysis.get('old_submissions', 0)
        if old_submissions > 50:
            recommendations.append(f"æ¸…ç† {old_submissions} ä¸ªæ—§æŠ•ç¨¿è®°å½•")
        
        log_size = data_analysis.get('log_files_size', 0)
        if log_size > 20:
            recommendations.append(f"æ¸…ç†æ—¥å¿—æ–‡ä»¶ ({log_size:.1f}MB)")
        
        return {
            'recommendations': recommendations,
            'urgency': data_analysis.get('cleanup_urgency', 'low'),
            'estimated_savings': f"{log_size + old_submissions * 0.1:.1f}MB"
        }
    
    def _send_cleanup_recommendations(self, context: CallbackContext, cleanup_plan: Dict[str, Any]):
        """å‘é€æ¸…ç†å»ºè®®"""
        recommendations = cleanup_plan.get('recommendations', [])
        if not recommendations:
            return
        
        message = (
            "ğŸ§¹ æ™ºèƒ½æ¸…ç†å»ºè®®\n\n"
            + "\n".join(f"â€¢ {rec}" for rec in recommendations)
            + f"\n\né¢„è®¡èŠ‚çœç©ºé—´: {cleanup_plan.get('estimated_savings', 'N/A')}"
            + f"\nç´§æ€¥åº¦: {cleanup_plan.get('urgency', 'low')}"
        )
        
        if ADMIN_IDS:
            try:
                context.bot.send_message(chat_id=ADMIN_IDS[0], text=message)
                logger.info("æ™ºèƒ½æ¸…ç†å»ºè®®å·²å‘é€")
            except Exception as e:
                logger.error(f"å‘é€æ¸…ç†å»ºè®®å¤±è´¥: {e}")
    
    def _collect_weekly_data(self) -> Dict[str, Any]:
        """æ”¶é›†å‘¨æ•°æ®"""
        return {
            'total_submissions': 150,
            'approved_submissions': 120,
            'rejected_submissions': 20,
            'pending_submissions': 10,
            'new_users': 25,
            'active_users': 80
        }
    
    def _generate_comprehensive_report(self, data: Dict[str, Any], period: str) -> str:
        """ç”Ÿæˆç»¼åˆæŠ¥å‘Š"""
        return f"""ğŸ“Š {period.title()} ç³»ç»ŸæŠ¥å‘Š

ğŸ“ æŠ•ç¨¿ç»Ÿè®¡:
â€¢ æ€»æŠ•ç¨¿: {data.get('total_submissions', 0)}
â€¢ å·²é€šè¿‡: {data.get('approved_submissions', 0)}
â€¢ å·²æ‹’ç»: {data.get('rejected_submissions', 0)}
â€¢ å¾…å®¡æ ¸: {data.get('pending_submissions', 0)}

ğŸ‘¥ ç”¨æˆ·ç»Ÿè®¡:
â€¢ æ–°ç”¨æˆ·: {data.get('new_users', 0)}
â€¢ æ´»è·ƒç”¨æˆ·: {data.get('active_users', 0)}

é€šè¿‡ç‡: {data.get('approved_submissions', 0) / max(data.get('total_submissions', 1), 1) * 100:.1f}%"""
    
    def _send_weekly_report(self, context: CallbackContext, report: str):
        """å‘é€å‘¨æŠ¥"""
        for admin_id in ADMIN_IDS:
            try:
                context.bot.send_message(chat_id=admin_id, text=report)
            except Exception as e:
                logger.error(f"å‘é€å‘¨æŠ¥ç»™ç®¡ç†å‘˜ {admin_id} å¤±è´¥: {e}")
        
        logger.info("å‘¨æŠ¥å·²å‘é€ç»™æ‰€æœ‰ç®¡ç†å‘˜")
    
    def _detect_anomalies(self) -> List[Dict[str, Any]]:
        """æ£€æµ‹å¼‚å¸¸"""
        return []  # æš‚æ—¶è¿”å›ç©ºåˆ—è¡¨
    
    def _handle_anomalies(self, context: CallbackContext, anomalies: List[Dict[str, Any]]):
        """å¤„ç†å¼‚å¸¸"""
        for anomaly in anomalies:
            message = f"âš ï¸ å¼‚å¸¸æ£€æµ‹: {anomaly.get('description', 'æœªçŸ¥å¼‚å¸¸')}"
            
            for admin_id in ADMIN_IDS:
                try:
                    context.bot.send_message(chat_id=admin_id, text=message)
                except Exception as e:
                    logger.error(f"å‘é€å¼‚å¸¸è­¦æŠ¥å¤±è´¥: {e}")
    
    def _record_task_execution(self, task_name: str, execution_time: float, success: bool):
        """è®°å½•ä»»åŠ¡æ‰§è¡Œ"""
        execution_record = {
            'timestamp': get_beijing_now(),
            'execution_time': execution_time,
            'success': success
        }
        
        task_execution_history[task_name].append(execution_record)
        
        status = "æˆåŠŸ" if success else "å¤±è´¥"
        log_system_event(
            f"TASK_EXECUTION_{task_name.upper()}", 
            f"ä»»åŠ¡{status}ï¼Œè€—æ—¶{execution_time:.2f}ç§’"
        )

# åˆ›å»ºå…¨å±€è°ƒåº¦å™¨å®ä¾‹
advanced_scheduler = AdvancedScheduler()

# è®¾ç½®å‡½æ•°
async def setup_advanced_scheduler(context: CallbackContext):
    """è®¾ç½®é«˜çº§è°ƒåº¦å™¨"""
    await advanced_scheduler.setup_enhanced_tasks(context)